<!DOCTYPE html>
<html lang="en">

<head>
    <title>Zhang Group</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">


    <link href="https://fonts.googleapis.com/css?family=B612+Mono|Cabin:400,700&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="fonts/icomoon/style.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"
          integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">

    <link rel="stylesheet" href="css/jquery-ui.css">
    <link rel="stylesheet" href="css/owl.carousel.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">

    <link rel="stylesheet" href="css/jquery.fancybox.min.css">

    <link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">

    <link rel="stylesheet" href="css/aos.css">
    <link href="css/jquery.mb.YTPlayer.min.css" media="all" rel="stylesheet" type="text/css">

    <link rel="stylesheet" href="css/style.css">
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->


</head>

<body data-spy="scroll" data-target=".site-navbar-target" data-offset="300">

<div class="site-wrap">

    <div class="site-mobile-menu site-navbar-target">
        <div class="site-mobile-menu-header">
            <div class="site-mobile-menu-close mt-3">
                <span class="icon-close2 js-menu-toggle"></span>
            </div>
        </div>
        <div class="site-mobile-menu-body"></div>
    </div>

    <div class="header-top">
        <div class="container" style="padding:20px">
            <div class="row align-items-center">
                <!-- <div class="col-12 col-lg-6 d-flex"> -->
                <img src="./logo.png" width="25%">
                    <a class="ml-auto site-logo">
                             &nbsp<b style="color: rgb(71, 71, 71)"></b>Zhang Group @ UT Southwestern Medical Center
                    </a>
                    <a href="#"
                       class="ml-auto d-inline-block d-lg-none site-menu-toggle js-menu-toggle text-black"><span
                            class="icon-menu h3"></span></a>

                <!-- </div> -->
                <!-- <div class="col-12 col-lg-6 ml-auto d-flex">
                    <div class="ml-md-auto top-social d-none d-lg-inline-block">
                        <a href="#" class="d-inline-block p-3"> </a>
                        <a href="#" class="d-inline-block p-3"> </a>
                        <a href="#" class="d-inline-block p-3"> </a>
                    </div>

                </div> -->
                <!--          <div class="col-6 d-block d-lg-none text-right">-->

            </div>
        </div>
    </div>

    
    <div class="site-navbar py-2 js-sticky-header site-navbar-target d-none pl-0 d-lg-block" role="banner">

        <div class="container" style="padding-right=10%">
            <div class="d-flex align-items-right">
                <!-- <div class="mr-auto">
                    <a href="index.html">
                       <img src="./logo.png" width="10%"/>
                             &nbsp&nbsp<b>V</b>isual <b>I</b>nformatics Group @ University of <b>T</b>exas at <b>A</b>ustin
                    </a>
                </div> -->
                <div class="ml-auto">
                    <nav class="site-navigation position-relative text-right" role="navigation">
                        <ul class="site-menu main-menu js-clone-nav mr-auto d-none pl-0 d-lg-block">
                            <li class="active">
                                <a href="index.html" class="nav-link text-right">Home</a>
                            </li>
                            <li>
                                <a href="research.html" class="nav-link text-left">PI & Research</a>
                            </li>
                            <li>
                                <a href="publication.html" class="nav-link text-left">Publication</a>
                            </li>
                            <li>
                                <a href="group.html" class="nav-link text-left">Group</a>
                            </li>
                            <li>
                                <a href="resource.html" class="nav-link text-left">Resource</a>
                            </li>
                            <li>
                                <a href="prospective_students.html" class="nav-link text-left">Opening</a>
                            </li>
                            <!-- <li class="nav-item dropdown">
                                              <a class="nav-link dropdown-toggle" href="challenge.html" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                   Challenge
                                 </a>
                                          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                                           <a class="dropdown-item" href="challenge1.html">Tiny Object Detection Challenge</a>
                                           <a class="dropdown-item" href="challenge2.html">Image Restoration for UDC Challenge</a>
                                         </div>
                            </li>
                            <li>
                                <a href="callforpapers.html" class="nav-link text-left">Call for Papers</a>
                            </li>

                            <li>
                                <a href="speakers.html" class="nav-link text-left">Invited Speakers</a>
                            </li>

                            <li class="nav-item dropdown">
                                <a class="nav-link dropdown-toggle" href="challenge.html" id="navbarDropdown"
                                   role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                    Previous
                                </a>
                                <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                                    <a class="dropdown-item" href="https://yuqian2.wixsite.com/forlq">RLQ'19</a>
                                </div>
                            </li> -->
                        </ul>
                    </nav>

                </div>

            </div>
        </div>

    </div>

</div>



<div class="site-section">
    <div class="container">
        <div class="row">
            <div class="col-lg-12">

                
                <div class="section-title" style="margin-bottom:20px">
                    <h2>About PI</h2>
                </div>
                <div class="trend-entry d-flex">
                    <div class="trend-contents">
                        <p>Professor You Zhang <a href="https://scholar.google.com/citations?user=VzdJe_4AAAAJ">[Google Scholar]</a> is a Associate Professor and </p>

                    </div>
                </div>



                <div class="section-title" style="margin-bottom:20px">
                    <h2>About Our Research</h2>
                </div>
                <div class="trend-entry d-flex">
                    <div class="trend-contents">


                     <p>At Zhang group, we have <b style="color:rgb(71, 71, 71)">unusually broad, and forever-evolving</b> research interests spanning from the <b style="color:rgb(71, 71, 71)">theory</b>  to the <b style="color:rgb(71, 71, 71)">application</b> aspects of machine learning (ML). Our current "research keywords" include, but are not limited to:  sparsity (from classical optimization to modern neural networks); efficient training, inference or transfer (especially, of large language models); neural scaling law; robustness and trustworthiness; learning to optimize (L2O); generative AI; graph learning, and more. Below, we describe a few organized themes that are driving our group's latest efforts.</p>
                    </ul>

                        <h4>Theme 1: Efficient and Scalable Learning through Intrinsic Low Dimensionality</h4>
                        <p>

                        One of the most fundamental reasons for the existence and emergence of intelligence is that the world is not fully random, but highly structured and predictable. Hence, a fundamental purpose and function of intelligence or science is to learn parsimonious models (or laws) for such predicable structures, from massive sensed data of the world. The traditional approach to algorithm design, based around parametric models for specific structures of signals and measurements – say sparse and low-rank models – and the associated optimization toolkit, is now significantly enriched with data-driven learning-based techniques. Nevertheless, the successes of both modern data-driven and classic model-based paradigms rely crucially on correctly identifying the low-dimensional structures present in real-world data, to the extent that we see the roles of "learning" and "compression" of data processing algorithms – whether explicit or implicit, as with deep networks – as inextricably linked.  Most recently, the advent of foundation models (LLMs) has led some to posit that parsimony and compression itself are a fundamental part of the learning objective of an intelligent system, connecting to ideas from neuroscience on compression as a guiding principle for the brain representing the sensory data of the world. </p>

                        <p>In our group, the pursuit of learning with low-dimensional models or representations occupies a central place. For example, we have contributed many well-recognized works to laying theoretical foundations for sparse neural networks’ efficiency, optimization, and generalization; and to demonstrating their empirical promise, from TinyML to large foundation model (e.g. LLM) applications. We also created a <a href="https://arxiv.org/abs/2302.02596">short handbook for sparse NN researchers</a>.
                        </p>

                        <b style="color:rgb(68, 68, 68)"><i>Selected Notable Works:</i></b>
                        <li>A. Jaiswal*, S. Liu*, T. Chen*, Z Wang, <b style="color:rgb(71, 71, 71)">"The Emergence of Essential Sparsity in Large Pre-trained Models: The Weights that Matter”</b>, Advances in Neural Information Processing Systems (NeurIPS), 2023. <a href="https://arxiv.org/abs/2306.03805">[Paper]</a> <a href="https://github.com/Zhang Group-Group/essential_sparsity">[Code] </a> </li>
                        <li>Z. Zhang*, Y. Sheng, T. Zhou, T. Chen*, L. Zheng, R. Cai*, Z. Song, Y. Tian, C. Ré, C. Barrett, Z. Wang, and B. Chen, <b style="color:rgb(71, 71, 71)">"H<sub>2</sub>O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models”</b>, Advances in Neural Information Processing Systems (NeurIPS), 2023. <a href="https://arxiv.org/abs//2306.14048">[Paper]</a> <a href="https://github.com/FMInference/H2O">[Code] </a> </li>
                        <li>D. Hoang*, S. Liu*, R. Marculescu, and Z. Wang, <b style="color:rgb(71, 71, 71)">"Revisiting Pruning at Initialization Through the Lens of Ramanujan Graph”</b>, International Conference on Learning Representations (ICLR), 2023. (Oral) <a href="https://openreview.net/forum?id=uVcDssQff_">[Paper]</a> <a href="https://github.com/Zhang Group-Group/ramanujan-on-pai">[Code] </a> </li>
                        <li>T. Chen*, Z. Zhang*, A. Jaiswal*, S. Liu*, and Z. Wang, <b style="color:rgb(71, 71, 71)">"Sparse MoE as the New Dropout: Scaling Dense and Self-Slimmable Transformers”</b>, International Conference on Learning Representations (ICLR), 2023. (Spotlight) <a href="https://openreview.net/forum?id=w1hwFUb_81">[Paper]</a> <a href="https://github.com/Zhang Group-Group/Random-MoE-as-Dropout">[Code] </a> </li>
                        <li>T. Chen*, J. Frankle, S. Chang, S. Liu, Y. Zhang, Z. Wang, and M. Carbin, <b style="color:rgb(71, 71, 71)">“The Lottery Ticket Hypothesis for Pre-trained BERT Networks”</b>, Advances in Neural Information Processing Systems (NeurIPS), 2020. <a href="https://proceedings.neurips.cc/paper_files/paper/2020/file/b6af2c9703f203a2794be03d443af2e3-Paper.pdf">[Paper]</a> <a href="https://github.com/Zhang Group-Group/BERT-Tickets">[Code]</a></li>
                         <br>



                        <h4>Theme 2: New Architectures and Model Scaling </h4>
                        <p>
                           We are devoted to studying emerging model families that promise to become future “universal” workhorses or "foundational models": two such examples are transformers (especially LLMs) and graph neural networks, and many projects here are owing to our close collaboration with industry leaders. We are meanwhile enthusiastic about AutoML & neural scaling law, on both consolidating its theoretical underpinnings ("why choosing this model, not that one?") and broadening its practical applicability ("what more can be automated, and how to do it better?"). State-of-the-art ML systems consist of complex pipelines with multiplied design choices. We see AutoML & neural scaling law as a central hub in addressing those design challenges; it also proves to be a powerful scientific tool for understanding many ad-hoc choices of network architectures or hyperparameters (often aided by the deep learning theory). 
                        </p>

                        <b style="color:rgb(68, 68, 68)"><i>Selected Notable Works:</i></b>
                        <li>P. Wang*, R. Panda, L. Hennigen, P. Greengard, L. Karlinsky, R. Feris, D. Cox, Z. Wang, and Y. Kim, <b style="color:rgb(71, 71, 71)">"Learning to Grow Pretrained Models for Efficient Transformer Training”</b>, International Conference on Learning Representations (ICLR), 2023. (Spotlight) <a href="https://openreview.net/forum?id=cDYRS5iZ16f">[Paper]</a> <a href="https://github.com/Zhang Group-Group/LiGO">[Code] </a> </li>
                        <li>P. Wang*, R. Panda, and Z. Wang, <b style="color:rgb(71, 71, 71)">“Data Efficient Neural Scaling Law via Model Reusing”</b>, International Conference on Machine Learning (ICML), 2023. <a href="https://proceedings.mlr.press/v202/wang23aa.html">[Paper]</a> <a href="https://github.com/Zhang Group-Group/Data-Efficient-Scaling">[Code] </a> </li>
                        <li>P. Wang*, W. Zheng*, T. Chen*, and Z. Wang, <b style="color:rgb(71, 71, 71)">“Anti-Oversmoothing in Deep Vision Transformers via the Fourier Domain Analysis: From Theory to Practice”</b>, International Conference on Learning Representations (ICLR), 2022. <a href="https://openreview.net/forum?id=O476oWmiNNp">[Paper]</a> <a href="https://github.com/Zhang Group-Group/ViT-Anti-Oversmoothing">[Code]</a></li>
                        <li>W. Chen*, X. Gong*, and Z. Wang, <b style="color:rgb(71, 71, 71)">“Neural Architecture Search on ImageNet in Four GPU Hours: A Theoretically Inspired Perspective”</b>, International Conference on Learning Representations (ICLR), 2021. <a href="https://openreview.net/forum?id=Cnon5ezMHtu">[Paper]</a> <a href="https://github.com/Zhang Group-Group/TENAS">[Code]</a> 
                        <li>Y. You*, T. Chen*, Y. Sui, T. Chen, Z. Wang, and Y. Shen, <b style="color:rgb(71, 71, 71)">“Graph Contrastive Learning with Augmentations”</b>, Advances in Neural Information Processing Systems (NeurIPS), 2020. <a href="https://proceedings.nips.cc/paper/2020/file/3fe230348e9a12c13120749e3f9fa4cd-Paper.pdf">[Paper]</a> <a href="https://github.com/Zhang Group-Group/GraphCL">[Code]</a></li>
                         <br>



                        <h4>Theme 3: Generative AI for 2D/3D Visual Synthesis and Editing</h4>
                        <p>
                            Our group's earlier (pre-2021) work includes several influential algorithms for image enhancement and editing “in the wild,” many of which are based on Generative Adversarial Networks (GANs). We pioneered a few innovative GAN architectural designs (TransGAN, DeblurGAN-v2, EnlightenGAN, AutoGAN) that are now widely adopted by the community. More recently (post-2021), we have steered our focus to two new areas: (i) 3D reconstruction and novel view synthesis, via Neural Radiance Fields (NeRF); (2) the new generation of multi-modality GenAI, leveraging the latest workhorse of diffusion models (text2image, text2video, text-to-3D, etc.)
                        </p>


                        <b style="color:rgb(68, 68, 68)"><i>Selected Notable Works:</i></b>
                        <li>D. Xu*, Y. Jiang*, P. Wang*, Z. Fan*, Y. Wang*, and Z. Wang, <b style="color:rgb(71, 71, 71)">"NeuralLift-360: Lifting An In-the-wild 2D Photo to A 3D Object with 360◦ Views”</b>, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023. (Highlight) <a href="https://arxiv.org/abs/2211.16431">[Paper]</a> <a href="https://Zhang Group-group.github.io/NeuralLift-360/">[Code] </a> </li>
                        <li>L. Khachatryan, A. Movsisyan, V. Tadevosyan, R. Henschel, Z. Wang, S. Navasardyan, and H. Shi, <b style="color:rgb(71, 71, 71)">"Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators”</b>, IEEE International Conference on Computer Vision (ICCV), 2023. (Oral) <a href="https://arxiv.org/abs/2303.13439">[Paper]</a> <a href="https://github.com/Picsart-AI-Research/Text2Video-Zero">[Code] </a> </li>
                        <li>M. Varma*, P. Wang*, X. Chen*, T. Chen*, S. Venugopalan, and Z. Wang, <b style="color:rgb(71, 71, 71)">"Is Attention All That NeRF Needs?”</b>, International Conference on Learning Representations (ICLR), 2023. <a href="https://openreview.net/forum?id=xE-LtsE-xx">[Paper]</a> <a href="https://github.com/Zhang Group-Group/GNT">[Code]</a> </li>
                        <li>D. Xu*, Y. Jiang*, P. Wang*, Z. Fan*, H. Shi, and Z. Wang, <b style="color:rgb(71, 71, 71)">“SinNeRF: Training Neural Radiance Field on Complex Scenes from a Single Image”</b>, European Conference on Computer Vision (ECCV), 2022. <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136820712.pdf">[Paper]</a> <a href="https://Zhang Group-group.github.io/SinNeRF/">[Code] </a> </li>
                        <li>Y. Jiang*, S. Chang, and Z. Wang, <b style="color:rgb(71, 71, 71)">“TransGAN: Two Pure Transformers Can Make One Strong GAN, and That Can Scale Up”</b>, Advances in Neural Information Processing Systems (NeurIPS), 2021. <a href="https://proceedings.neurips.cc/paper/2021/file/7c220a2091c26a7f5e9f1cfb099511e3-Paper.pdf">[Paper]</a> <a href="https://github.com/Zhang Group-Group/TransGAN">[Code]</a></li>
                         <br>



                        <h4>Theme 4: Learning to Optimize (L2O) </h4>
                        <p>
                            L2O is an emerging paradigm that leverages ML to automatically develop an optimization algorithm. It demonstrates many practical benefits including faster convergence and better solution quality. Over the past five years, we have spearheaded an ever-growing line of L2O works that significantly expand both rigorous theories (L2O convergence, worst-case/average-case generalization, adaptation, uncertainty quantification, and interpretability), and practical adoption (inverse problems in computational sensing/imaging, large model training, private training, protein docking, AI for finance, among others). Please refer to the <a href="https://jmlr.org/papers/volume23/21-0308/21-0308.pdf">L2O Primer</a> and <a href="https://github.com/Zhang Group-Group/Open-L2O">Open L2O toolbox</a> that we presented for this community.
                        </p>

                        <b style="color:rgb(68, 68, 68)"><i>Selected Notable Works:</i></b>
                        <li>J. Yang, T. Chen*, M. Zhu*, F. He, D. Tao, Y. Liang, and Z. Wang, <b style="color:rgb(71, 71, 71)">"Learning to Generalize Provably in Learning to Optimize”</b>, International Conference on Artificial Intelligence and Statistics (AISTATS), 2023. <a href="https://proceedings.mlr.press/v206/yang23h/yang23h.pdf">[Paper]</a> <a href="https://github.com/Zhang Group-Group/Open-L2O/tree/main/Model_Free_L2O/L2O-Entropy">[Code] </a> </li>
                        <li>(α-β) T. Chen*, X. Chen*, W. Chen*, H. Heaton, J. Liu, Z. Wang, and W. Yin, <b style="color:rgb(71, 71, 71)">“Learning to Optimize: A Primer and A Benchmark”</b>, Journal of Machine Learning Research (JMLR), 2022. <a href="https://jmlr.org/papers/v23/21-0308.html">[Paper]</a> <a href="https://github.com/Zhang Group-Group/Open-L2O">[Code]</a></li> 
                        <li>W. Zheng*, T. Chen*, T. Hu*, and Z. Wang, <b style="color:rgb(71, 71, 71)">“Symbolic Learning to Optimize: Towards Interpretability and Scalability”</b>, International Conference on Learning Representations (ICLR), 2022. <a href="https://openreview.net/forum?id=ef0nInZHKIC">[Paper]</a> <a href="https://github.com/Zhang Group-Group/Symbolic-Learning-To-Optimize">[Code]</a></li>
                        <li>J. Liu, X. Chen*, Z. Wang, and W. Yin, <b style="color:rgb(71, 71, 71)">“ALISTA: Analytic Weights Are As Good As Learned Weights in LISTA”</b>, International Conference on Learning Representations (ICLR), 2019. <a href="https://openreview.net/forum?id=B1lnzn0ctQ">[Paper]</a> <a href="https://github.com/TAMU-Zhang Group/ALISTA">[Code]</a></li>
                         <br>


                        <h4>Theme 5: Machine Learning for Good (Robustness, Privacy, Fairness, & AI4Science)</h4>
                        <p>
                            As ML systems (in particular, computer vision and LLM) are influencing all facets of our daily life, it is now commonplace to see evidence on the untrustworthiness or harmful impacts of ML systems in high-stake environments. We have strived to build ML algorithms that are resilient to various environment degradations, perturbations, adversarial attacks, and privacy threats - as overviewed in our  <a href="https://dl.acm.org/doi/full/10.1145/3551385">ML Safety Primer</a>. We are also keen on developing AI4sicnece (protein, medical image, material science), and AI for the Common Good (our <a href="https://bridgingbarriers.utexas.edu/good-systems/projects/being-watched-embedding-ethics-in-public-cameras">Good Systems</a> project)
                        </p>

                        <b style="color:rgb(68, 68, 68)"><i>Selected Notable Works:</i></b>
                        <li> G. Holste*, E. Oikonomou, B. Mortazavi, A. Coppi, K. Faridi, E. Miller, J. Forrest, R. McNamara, L. Ohno-Machado, N. Yuan, A. Gupta, D. Ouyang, H. Krumholz, Z. Wang, and R. Khera, <b style="color:rgb(71, 71, 71)">“Severe Aortic Stenosis Detection by Deep Learning Applied to Echocardiography”</b>, European Heart Journal (EHJ), 2023. <a href="https://academic.oup.com/eurheartj/advance-article/doi/10.1093/eurheartj/ehad456/7248551">[Paper]</a> <a href="https://github.com/CarDS-Yale/echo-severe-AS">[Code]</a></li>
                        <li>T. Chen*, C. Gong, D. Diaz, X. Chen*, J. Wells, Q. Liu, Z. Wang, A. Ellington, A. Dimakis, and A. Klivans, <b style="color:rgb(71, 71, 71)">"HotProtein: A Novel Framework for Protein Thermostability Prediction and Editing”</b>, International Conference on Learning Representations (ICLR), 2023. <a href="https://openreview.net/forum?id=YDJRFWBMNby">[Paper]</a> <a href="https://github.com/Zhang Group-Group/HotProtein">[Code]</a> </li>
                        <li>H. Wang*, C. Xiao, J. Kossaifi, Z. Yu, A. Anandkumar, and Z. Wang, <b style="color:rgb(71, 71, 71)">“AugMax: Adversarial Composition of Random Augmentations for Robust Training”</b>, Advances in Neural Information Processing Systems (NeurIPS), 2021. <a href="https://proceedings.neurips.cc/paper/2021/file/01e9565cecc4e989123f9620c1d09c09-Paper.pdf">[Paper]</a> <a href="https://github.com/Zhang Group-Group/AugMax">[Code]</a></li>
                       <li>Z. Wu*, H. Wang*, Z. Wang, H. Jin, and Z. Wang, <b style="color:rgb(71, 71, 71)">“Privacy-Preserving Deep Action Recognition: An Adversarial Learning Framework and A New Dataset”</b>, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2020. <a href="https://ieeexplore.ieee.org/abstract/document/9207852">[Paper]</a> <a href="https://github.com/Zhang Group-Group/PA-HMDB51">[Code]</a></li>
                         <br>
                        <!-- <br> -->
                        <h5><a href="./prospective_students.html">Prospective Students Shall Read More...</a></h5>
                    </div>
                </div>




            <div class="section-title" style="padding-top: 20px">
                <h2>Sponsor</h2>
            </div>
            <div class="trend-entry d-flex">
                <div class="row justify-content-md-center">
                    <div>
                        <img src="./123.png" width="100%"/>
                    </div>
                </div>
            </div>
        </div>

        </div>
    </div>

        
<!-- END section -->


<div class="footer">
    <div class="container">
        <div class="row">
            <div class="col-12">
                <div class="copyright">
                    <p>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                        Copyright &copy;<script>document.write(new Date().getFullYear());</script>
                        All rights reserved | Built upon <a
                            href="https://colorlib.com" target="_blank">Colorlib</a>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                        </p>
                        
                </div>
            </div>
        </div>
    </div>
</div>

</div>
<!-- .site-wrap -->


<!-- loader -->
<!-- <div id="loader" class="show fullscreen">
    <svg class="circular" width="48px" height="48px">
        <circle class="path-bg" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke="#eeeeee"/>
        <circle class="path" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke-miterlimit="10"
                stroke="#ff5e15"/>
    </svg>
</div> -->

<script src="js/jquery-3.3.1.min.js"></script>
<script src="js/jquery-migrate-3.0.1.min.js"></script>
<script src="js/jquery-ui.js"></script>
<script src="js/popper.min.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/owl.carousel.min.js"></script>
<script src="js/jquery.stellar.min.js"></script>
<script src="js/jquery.countdown.min.js"></script>
<script src="js/bootstrap-datepicker.min.js"></script>
<script src="js/jquery.easing.1.3.js"></script>
<script src="js/aos.js"></script>
<script src="js/jquery.fancybox.min.js"></script>
<script src="js/jquery.sticky.js"></script>
<script src="js/jquery.mb.YTPlayer.min.js"></script>

<script src="js/main.js"></script>

</body>

</html>
